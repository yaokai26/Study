## 1.Synchronized和lock的区别
### 从功能角度来看，两者都是java中用来解决线程安全的工具
### 从特性来看
 * Synchronized是关键字，Lock是JUC包中的接口，这个接口有很多的实现，其中就包括ReentrantLock可重入锁
 * Synchronized通过修饰方法或者修饰代码块这两种粒度，修饰在代码块上可以通过Synchronized加锁对象的生命周期来控制锁的作用范围，如果锁的对象是静态对象或者类对象，那么这个锁就是全局锁，
  如果锁对象是普通实例，那么锁的范围就取决于对象的生命周期，Lock锁的粒度是通过它提供的lock()和unlock()方法决定的，包裹在这两个方法之间的代码能够保证线程安全，而锁的作用域取决于Lock实例的生命周期
 * Lock比Synchronized的灵活性更高，它可以决定什么时候加锁，什么时候释放锁，只需要调用lock()和unlock()就行，同时lock还提供了非阻塞的竞争锁方法tryLock().Synchronized由于是关键字，无法实现非阻塞竞争
   锁的方法，而且Synchronized锁的释放是被动的，只有当同步代码块执行完成或者代码出现异常才会释放。
 * Lock提供了公平锁和非公平锁的机制，公平锁指线程竞争锁资源时，如果已经有其他线程正在排队等待，那么当前竞争锁资源的线程无法插队，非公平锁就是无论是否有线程在排队，都会去竞争。Synchronized只提供了非公平锁
### 从性能看，Sychronized和lock差异不大，Synchronized引入了偏向锁、轻量级锁、重量级锁以及锁升级的方式来优化性能，Lock则用到了自旋锁的方式来实现性能优化

## 2.线程池如何知道一个线程的任务已经执行完成
* 线程池提供了一个isTerminated()方法，可以判断线程池的运行状态，一旦线程池的运行状态是Terminated，就意味着线程池中的所有任务已经执行完了
* 在线程池中有一个submit()方法，他提供了一个Future的返回值，通过Future.get()来获得任务的执行结果，在线程池中的任务没有执行完成之前，这个方法会一直阻塞，直到任务结束。所以通过future.get()方法正常返回，也就意味着任务完成
* 可以引入CountDownLatch计数器，并且计数器为1，当线程池代码块后面调用await()方法阻塞主线程，然后当传入到线程池中的任务执行完后，调用countDown()方法表示任务执行结束，最后计数器归零，唤醒阻塞在await()方法的线程

## 3.谈谈对AQS的理解
### AQS是AbstractQueuedSynchronizer的简称,是并发编程中比较核心的组件.
### AQS是多线程同步器,他是J.U.C包中多个组件的底层实现,如Lock,CountDownLatch,Semaphore等都用到了AQS,本质上来说AQS提供了两种锁机制,一种是排他锁,一种是共享锁.
### 排他锁就是存在多线程同时竞争同一共享资源,同一时刻只允许一个线程访问共享资源,Lock中的ReentrantLock重入锁就用到了AQS的排他锁.
### 共享锁就是同一时刻允许多个线程同事获得锁资源,比如CountDownLatch和Semaphore都是用到AQS的共享锁功能


## 4.什么是消息队列
### 消息队列Message Queue简称MQ,主要由3个部分组成
* 生产者Producer,队列的发起方
* 代理Broker,负责消息的存储,投递等功能的实现
* 消费者Consumer,消息的调用者
### 消息队列主要的应用场景有
* 异步处理,对实时性要求不高的场景
* 应用解耦,把相关但是耦合程度不高的系统联系起来
* 流量削峰,大流量入口且短时间业务需求处理不完的服务中心
### 消息队列中间件主要有ActiveMQ,RabbitMQ,RocketMQ,Kafka,中小型公司,低吞吐量用ActiveMQ,RabbitMQ比较合适,大数据高吞吐的公司一般选用kafka和RocketMQ

## 5.分布式锁
Redis提供了SETNX命令可以实现锁的排他性,当key不存在就返回1,当key存在就返回0,然后用expire设置锁的失效时间,防止死锁.
![附图1](https://github.com/yaokai26/Images/blob/master/21.png)\
使用Redisson实现分布式锁的三个步骤
* 获取锁 RLock redissonLock = redisson.getLock(lockKey);
* 加锁,实现锁续命功能 redissonLock.lock();
* 释放锁 redissonLock.unlock();

## 6.ThreadLocal含义和原理
### ThreadLocal是一种线程隔离机制,它提供了多线程环境下对于共享变量访问的安全性,以空间换时间.他的具体实现原理是,在Thread类里有一个成员变量ThreadLocalMap,他专门来存储当前线程的共享变量副本,后面这个线程对于共享变量的操作,都是从这个map里进行变更,不会影响全局共享变量的值.
### ThreadLocal使用不当会出现内存泄漏.因为ThreadLocal中ThreadLocalMap包含了一个Entry数组,Entry本身是一个弱引用,被GC回收后,entry中的key为null,value有值,当时永远无法被访问,导致内存泄漏.

## 7.线程池
### ThreadPoolExecutor线程池参数详解:
* corePoolSize: 表示核心线程数,当前核心线程数没有达到corePoolSize,会创建新的线程来执行任务,即使当前核心线程池有空闲的线程,如果已经达到就不会继续创建
* maximumPoolSize:表示线程池能创建线程的最大个数
* keepAliveTime:表示线程空闲存活时间.如果当前线程池的线程数超过了corePoolSize,并且线程空闲时间超过了keepAliveTime,就会将这些线程销毁.这样可以尽可能降低资源消耗.默认只会回收非核心线程
* unit:时间单位
* workQueue:阻塞队列,用于保存任务的阻塞队列,可以使用ArrayBlockingQueue,LinkedBlockingQueue,SynchronousQueue,PriorityBlockingQueue
* threadFactory: 创建线程的工厂类
* handler: 饱和策略
当任务提交过来,判断核心线程池是否满,不满就创建核心线程,满了就把任务放到阻塞队列中去,如果阻塞队列已满,再判断线程池最大线程数量是否已满,未满就创建非核心线程,满了就执行拒绝策略.
![附图2](https://github.com/yaokai26/Images/blob/master/22.png)

### 线程池的拒绝策略
 * AbortPolicy 直接丢弃任务,抛出异常,这是默认策略
 * CallerRunsPolicy 只用调用者的所在线程来处理
 * DiscardOldestPolicy 丢弃等待队列最旧的任务,并执行当前任务
 * DiscardPolicy 直接丢弃任务,也不抛出异常

## 8.并行和并发的区别
### 并行,是指在多核CPU架构下,同一时刻可以执行多个线程的能力,在单核架构下,同一时刻只能运行一个线程
### 并发,是指在同一时刻CPU能同时处理的任务量,在单核CPU架构下,操作系统可以通过CPU时间片机制提升并发能力,多核CPU架构下,基于任务的并行能力以及CPU时间片机制来提升并发能力.

## 9.你知道哪些限流算法
* 固定窗口(计数器算法):在周期内累计访问次数达到设定的限流值,出发限流策略.
 ![附图3](https://github.com/yaokai26/Images/blob/master/23.png)
* 滑动窗口:将时间周期再细分为N个周期,分别记录每个小周期内的访问次数.当滑动窗口的格子划分得越多,那么滑动窗口的滚动就越平滑,限流统计就越精确,此方法可以解决固定窗口的临界问题
 ![附图4](https://github.com/yaokai26/Images/blob/master/24.png)
* 漏桶算法:请求直接放入漏桶,如当前容量已到达上限,则丢弃.漏桶以固定的速率释放请求,直到请求为空
* 令牌桶算法:程序以r的速度向令牌桶中增加令牌,直到令牌桶满.请求到达同时向令牌桶请求令牌,如获取到令牌则通过,否则出发限流策略
